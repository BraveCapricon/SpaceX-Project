{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h2>Table of Contents</h2>\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","    <li><a href=\"https://#Section_1\">Instructions</a></li>\n","    <li><a href=\"https://#Section_2\">About the Data</a></li>\n","    <li><a href=\"https://#Section_3\">Importing Data </a></li>\n","    <li><a href=\"https://#Section_4\">Data Preprocessing</a> </li>\n","    <li><a href=\"https://#Section_5\">Transforming Categorical Variables </a></li>\n","    <li><a href=\"https://#Section_6\">Train and Test Data Split </a></li>\n","    <li><a href=\"https://#Section_7\">Train Linear Regression, KNN, Decision Tree, Logistic Regression, and SVM models and return their appropriate accuracy scores</a></li>\n","</a></li>\n","</div>\n","<p>Estimated Time Needed: <strong>180 min</strong></p>\n","</div>\n","\n","<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["# Instructions\n"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, you will  practice all the classification algorithms that we learned in this course.\n","\n","After completing this notebook, you will need to upload it to the \"Submit Your Work and Review Your Peers\" section of the Final Project module.\n","\n","Below, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n","\n","We will use some of the algorithms taught in the course, specifically:\n","\n","1.  Linear Regression\n","2.  KNN\n","3.  Decision Trees\n","4.  Logistic Regression\n","5.  SVM\n","\n","We will evaluate our models using:\n","\n","1.  Accuracy Score\n","2.  Jaccard Index\n","3.  F1-Score\n","4.  LogLoss\n","5.  Mean Absolute Error\n","6.  Mean Squared Error\n","7.  R2-Score\n","\n","Finally, you will use your models to generate the report displaying the accuracy scores.\n"]},{"cell_type":"markdown","metadata":{},"source":["# About The Dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n","\n","The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n","\n","| Field         | Description                                           | Unit            | Type   |\n","| ------------- | ----------------------------------------------------- | --------------- | ------ |\n","| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n","| Location      | Location of the Observation                           | Location        | object |\n","| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n","| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n","| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n","| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n","| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n","| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n","| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n","| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n","| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n","| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n","| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n","| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n","| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n","| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n","| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n","| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n","| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n","| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n","| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n","| RainToday     | If there was rain today                               | Yes/No          | object |\n","| RISK_MM       | Amount of rain tomorrow                               | Millimeters     | float  |\n","| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n","\n","Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Import the required libraries**\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Surpress warnings:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","from sklearn import preprocessing\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","from sklearn.metrics import jaccard_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import log_loss\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import sklearn.metrics as metrics"]},{"cell_type":"markdown","metadata":{},"source":["### Importing the Dataset\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(3271, 22)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>MinTemp</th>\n","      <th>MaxTemp</th>\n","      <th>Rainfall</th>\n","      <th>Evaporation</th>\n","      <th>Sunshine</th>\n","      <th>WindGustDir</th>\n","      <th>WindGustSpeed</th>\n","      <th>WindDir9am</th>\n","      <th>WindDir3pm</th>\n","      <th>...</th>\n","      <th>Humidity9am</th>\n","      <th>Humidity3pm</th>\n","      <th>Pressure9am</th>\n","      <th>Pressure3pm</th>\n","      <th>Cloud9am</th>\n","      <th>Cloud3pm</th>\n","      <th>Temp9am</th>\n","      <th>Temp3pm</th>\n","      <th>RainToday</th>\n","      <th>RainTomorrow</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/1/2008</td>\n","      <td>19.5</td>\n","      <td>22.4</td>\n","      <td>15.6</td>\n","      <td>6.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>S</td>\n","      <td>SSW</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>84</td>\n","      <td>1017.6</td>\n","      <td>1017.4</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>20.7</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2/2/2008</td>\n","      <td>19.5</td>\n","      <td>25.6</td>\n","      <td>6.0</td>\n","      <td>3.4</td>\n","      <td>2.7</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>W</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>73</td>\n","      <td>1017.9</td>\n","      <td>1016.4</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>22.4</td>\n","      <td>24.8</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2/3/2008</td>\n","      <td>21.6</td>\n","      <td>24.5</td>\n","      <td>6.6</td>\n","      <td>2.4</td>\n","      <td>0.1</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>ESE</td>\n","      <td>ESE</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>86</td>\n","      <td>1016.7</td>\n","      <td>1015.6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>23.5</td>\n","      <td>23.0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2/4/2008</td>\n","      <td>20.2</td>\n","      <td>22.8</td>\n","      <td>18.8</td>\n","      <td>2.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>90</td>\n","      <td>1014.2</td>\n","      <td>1011.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>21.4</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2/5/2008</td>\n","      <td>19.7</td>\n","      <td>25.7</td>\n","      <td>77.4</td>\n","      <td>4.8</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>W</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>74</td>\n","      <td>1008.3</td>\n","      <td>1004.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>22.5</td>\n","      <td>25.5</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n","0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n","1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n","2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n","3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n","4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n","\n","   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n","0             41          S        SSW  ...           92           84   \n","1             41          W          E  ...           83           73   \n","2             41        ESE        ESE  ...           88           86   \n","3             41        NNE          E  ...           83           90   \n","4             41        NNE          W  ...           88           74   \n","\n","   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n","0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n","1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n","2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n","3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n","4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n","\n","   RainTomorrow  \n","0           Yes  \n","1           Yes  \n","2           Yes  \n","3           Yes  \n","4           Yes  \n","\n","[5 rows x 22 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv')\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["df.to_csv(\"Week6_Australia_Weather_Data.csv\", index=False)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["(3271, 22)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RainToday       2\n","WindGustDir    16\n","WindDir9am     16\n","WindDir3pm     16\n","dtype: int64\n"]}],"source":["# Count how many unique values we have for these columns below:\n","unique_counts = df[['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm']].nunique()\n","print(unique_counts)\n","# we need to know the count of unique values in order to know how many columns will be added at the end to make the table have binary values for columns"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Transforming Categorical Variables\n"]},{"cell_type":"markdown","metadata":{},"source":["First, we need to convert categorical variables to binary variables. We will use pandas `get_dummies()` method for this.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(3271, 22)\n","Index(['Date', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n","       'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n","       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n","       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n","       'Temp3pm', 'RainToday', 'RainTomorrow'],\n","      dtype='object')\n","(3271, 68)\n","Index(['Date', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n","       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n","       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n","       'Temp9am', 'Temp3pm', 'RainTomorrow', 'RainToday_No', 'RainToday_Yes',\n","       'WindGustDir_E', 'WindGustDir_ENE', 'WindGustDir_ESE', 'WindGustDir_N',\n","       'WindGustDir_NE', 'WindGustDir_NNE', 'WindGustDir_NNW',\n","       'WindGustDir_NW', 'WindGustDir_S', 'WindGustDir_SE', 'WindGustDir_SSE',\n","       'WindGustDir_SSW', 'WindGustDir_SW', 'WindGustDir_W', 'WindGustDir_WNW',\n","       'WindGustDir_WSW', 'WindDir9am_E', 'WindDir9am_ENE', 'WindDir9am_ESE',\n","       'WindDir9am_N', 'WindDir9am_NE', 'WindDir9am_NNE', 'WindDir9am_NNW',\n","       'WindDir9am_NW', 'WindDir9am_S', 'WindDir9am_SE', 'WindDir9am_SSE',\n","       'WindDir9am_SSW', 'WindDir9am_SW', 'WindDir9am_W', 'WindDir9am_WNW',\n","       'WindDir9am_WSW', 'WindDir3pm_E', 'WindDir3pm_ENE', 'WindDir3pm_ESE',\n","       'WindDir3pm_N', 'WindDir3pm_NE', 'WindDir3pm_NNE', 'WindDir3pm_NNW',\n","       'WindDir3pm_NW', 'WindDir3pm_S', 'WindDir3pm_SE', 'WindDir3pm_SSE',\n","       'WindDir3pm_SSW', 'WindDir3pm_SW', 'WindDir3pm_W', 'WindDir3pm_WNW',\n","       'WindDir3pm_WSW'],\n","      dtype='object')\n"]}],"source":["# This get_dummies function is used on the 4 specified categorical columns\n","# It will create new binary columns for each categorical column\n","df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])\n","print(df.shape)\n","print(df.columns)\n","print(df_sydney_processed.shape)\n","print(df_sydney_processed.columns)\n","# now the column names have an underscore and the categorical value of the initial column (i.e., WindGustDir has now 16 columns, WindDir9am has 16 columns...)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Data and Test Data\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we set our 'features' or x values and our Y or target variable.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df_sydney_processed.drop('Date',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Convert all column values to \"Float\"  \n","df_sydney_processed = df_sydney_processed.astype(float)\n","df_sydney_processed.to_csv(\"Week6_df_sydney_processed.csv\", index = False)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n","Y = df_sydney_processed['RainTomorrow']"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Regression\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train.shape= (2616, 66) Y_train.shape= (2616,)\n","X_test.shape= (655, 66) Y_test.shape= (655,)\n"]}],"source":["#Enter Your Code, Execute and take the Screenshot\n","X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n","print('X_train.shape=', X_train.shape, 'Y_train.shape=', Y_train.shape)\n","print('X_test.shape=', X_test.shape, 'Y_test.shape=', Y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients:  [-2.36936355e-02  1.30059424e-02  7.29650614e-04  6.49017543e-03\n"," -3.51617446e-02  4.23642728e-03  1.82835629e-03  7.90246630e-04\n","  9.56037542e-04  8.56183518e-03  7.69214842e-03 -9.23773793e-03\n"," -8.87251538e-03  1.00505139e-02  1.44632134e-02 -3.48030608e-03\n"," -1.69684356e+10 -1.69684356e+10 -1.15480277e+10 -1.15480277e+10\n"," -1.15480277e+10 -1.15480277e+10 -1.15480277e+10 -1.15480277e+10\n"," -1.15480277e+10 -1.15480277e+10 -1.15480277e+10 -1.15480277e+10\n"," -1.15480277e+10 -1.15480277e+10 -1.15480277e+10 -1.15480277e+10\n"," -1.15480277e+10 -1.15480277e+10  5.47490432e+09  5.47490432e+09\n","  5.47490432e+09  5.47490432e+09  5.47490432e+09  5.47490432e+09\n","  5.47490432e+09  5.47490432e+09  5.47490432e+09  5.47490432e+09\n","  5.47490432e+09  5.47490432e+09  5.47490432e+09  5.47490432e+09\n","  5.47490432e+09  5.47490432e+09 -1.50674603e+10 -1.50674603e+10\n"," -1.50674603e+10 -1.50674603e+10 -1.50674603e+10 -1.50674603e+10\n"," -1.50674603e+10 -1.50674603e+10 -1.50674603e+10 -1.50674603e+10\n"," -1.50674603e+10 -1.50674603e+10 -1.50674603e+10 -1.50674603e+10\n"," -1.50674603e+10 -1.50674603e+10]\n"]}],"source":["#Enter Your Code, Execute and take the Screenshot\n","from sklearn import linear_model\n","LinearReg = linear_model.LinearRegression()\n","x = np.asanyarray(X_train)\n","y = np.asanyarray(Y_train)\n","LinearReg.fit (x,y)\n","# The coefficients\n","print ('Coefficients: ', LinearReg.coef_)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["            Feature   Coefficient\n","0           MinTemp -2.369364e-02\n","1           MaxTemp  1.300594e-02\n","2          Rainfall  7.296506e-04\n","3       Evaporation  6.490175e-03\n","4          Sunshine -3.516174e-02\n","5     WindGustSpeed  4.236427e-03\n","6      WindSpeed9am  1.828356e-03\n","7      WindSpeed3pm  7.902466e-04\n","8       Humidity9am  9.560375e-04\n","9       Humidity3pm  8.561835e-03\n","10      Pressure9am  7.692148e-03\n","11      Pressure3pm -9.237738e-03\n","12         Cloud9am -8.872515e-03\n","13         Cloud3pm  1.005051e-02\n","14          Temp9am  1.446321e-02\n","15          Temp3pm -3.480306e-03\n","16     RainToday_No -1.696844e+10\n","17    RainToday_Yes -1.696844e+10\n","18    WindGustDir_E -1.154803e+10\n","19  WindGustDir_ENE -1.154803e+10\n"]}],"source":["coef_df = pd.DataFrame({'Feature': X_train.columns,'Coefficient': LinearReg.coef_})\n","print(coef_df.head(20))"]},{"cell_type":"markdown","metadata":{},"source":["#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Residual sum of squares: 0.12\n","Variance score: 0.43\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Jad\\Python\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n","  warnings.warn(\n","d:\\Jad\\Python\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n","  warnings.warn(\n"]}],"source":["y_hat= LinearReg.predict(X_test) # y_hat is a numpy array\n","\n","## Below is additional\n","print(\"Residual sum of squares: %.2f\"\n","      % np.mean((Y_test - y_hat) ** 2))\n","\n","# Explained variance score: 1 is perfect prediction\n","# print('Variance score: %.2f' % LinearReg.score(x1, y1)) \n","print('Variance score: %.2f' % LinearReg.score(X_test, Y_test)) "]},{"cell_type":"markdown","metadata":{},"source":["#### Q4) Using the `predictions` and the `y_test` dataframe to calculate the value for each metric using the appropriate function."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Absolute Error: 0.2563134695737416\n","Mean Squared Error: 0.11571819937516017\n","Linear Regression R2: 0.4271439065017988\n"]}],"source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Mean Absolute Error\n","LinearRegression_MAE = mean_absolute_error(Y_test, y_hat)\n","print('Mean Absolute Error:', LinearRegression_MAE)\n","\n","# Mean Squared Error\n","\n","LinearRegression_MSE = mean_squared_error(Y_test, y_hat)\n","print('Mean Squared Error:', LinearRegression_MSE)\n","\n","#LinearRegression_R2\n","LinearRegression_R2 = r2_score(Y_test, y_hat)\n","print('Linear Regression R2:', LinearRegression_R2)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        MAE       MSE        R2\n","0  0.256313  0.115718  0.427144\n","<class 'pandas.core.frame.DataFrame'>\n","<class 'list'>\n"]}],"source":["# See below i added square brackets to make the float value become a list in order to make it a dataframe\n","Report = pd.DataFrame({'MAE': [LinearRegression_MAE],'MSE': [LinearRegression_MSE], 'R2': [LinearRegression_R2]})\n","\n","## Additional\n","print(Report)\n","print(type(Report))\n","print(type([LinearRegression_MAE]))"]},{"cell_type":"markdown","metadata":{},"source":["### KNN\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4)</pre></div></div></div></div></div>"],"text/plain":["KNeighborsClassifier(n_neighbors=4)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Use KNeighborsCLassifier, its a function from the Scikit learn library. The function is a built-in KNN algorithm\n","from sklearn.neighbors import KNeighborsClassifier\n","k = 4\n","#Train Model\n","KNN4 = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n","KNN4"]},{"cell_type":"markdown","metadata":{},"source":["#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set Accuracy:  0.8612385321100917\n","Test set Accuracy:  0.8122137404580153\n"]}],"source":["predictions = KNN4.predict(X_test)\n","\n","# Additional\n","\n","print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, KNN4.predict(X_train)))\n","print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["#### Q8) Using the `predictions` and the `y_test` dataframe to calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score:  0.8122137404580153\n","Jaccard Index:  0.39408866995073893\n","F1 Score:  0.5653710247349824\n"]}],"source":["#KNN_Accuracy_Score\n","KNN_Accuracy_Score = accuracy_score(Y_test, predictions)\n","print(\"Accuracy Score: \", accuracy_score(Y_test, predictions))\n","\n","#KNN_JaccardIndex \n","KNN_JaccardIndex = jaccard_score(Y_test, predictions)\n","print(\"Jaccard Index: \", jaccard_score(Y_test, predictions))\n","\n","#KNN_F1_Score\n","KNN4_F1_Score = f1_score(Y_test, predictions)\n","print(\"F1 Score: \", f1_score(Y_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4)</pre></div></div></div></div></div>"],"text/plain":["DecisionTreeClassifier(criterion='entropy', max_depth=4)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.tree import DecisionTreeClassifier\n","import sklearn.tree as tree\n","\n","# In DecisionTreeClassifer, we can use different types of classifiers, we can use: 1) Gini Impurity, 2) Mean Squared Error, 3) Mean Absolute Error and 4) Entropy\n","# The default criterion is Gini - For this code line, we will use entropy to calculate the entropy (i.e., increase in information purity)\n","\n","Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4) # we limit how deep the tree will be (4), we do this to avoid model overfitting.\n","\n","Tree.fit(X_train,Y_train)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["predictions = Tree.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score:  0.8045801526717558\n","Jaccard Index:  0.3786407766990291\n","F1 Score:  0.5492957746478873\n"]}],"source":["# Accuracy_Score \n","Tree_Accuracy_Score = accuracy_score(Y_test, predictions)\n","print(\"Accuracy Score: \", accuracy_score(Y_test, predictions))\n","\n","# JaccardIndex \n","Tree_JaccardIndex = jaccard_score(Y_test, predictions)\n","print(\"Jaccard Index: \", jaccard_score(Y_test, predictions))\n","\n","# F1_Score\n","Tree_F1_Score = f1_score(Y_test, predictions)\n","print(\"F1 Score: \", f1_score(Y_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### Logistic Regression\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train.shape= (2616, 66) Y_train.shape= (2616,)\n","X_test.shape= (655, 66) Y_test.shape= (655,)\n"]}],"source":["X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=1)\n","print('X_train.shape=', X_train.shape, 'Y_train.shape=', Y_train.shape)\n","print('X_test.shape=', X_test.shape, 'Y_test.shape=', Y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(C=0.01, solver='liblinear')"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","# C = 0.01 shows a model with strong regularization\n","# liblinear is the solver (numerical optimizer) used for optimization\n","\n","LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\n","LR"]},{"cell_type":"markdown","metadata":{},"source":["#### Q14) Now, use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["predictions = LR.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q15) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score:  0.8274809160305343\n","Jaccard Index:  0.4840182648401826\n","F1 Score:  0.6523076923076923\n","Log Loss 6.218218065603417\n"]}],"source":["# Accuracy_Score\n","LR_Accuracy_Score = accuracy_score(Y_test, predictions)\n","print(\"Accuracy Score: \", accuracy_score(Y_test, predictions))\n","\n","# JaccardIndex \n","LR_JaccardIndex = jaccard_score(Y_test, predictions)\n","print(\"Jaccard Index: \", jaccard_score(Y_test, predictions))\n","\n","# F1_Score\n","LR_F1_Score = f1_score(Y_test, predictions)\n","print(\"F1 Score: \", f1_score(Y_test, predictions))\n","\n","# Log_Loss Logarithmic Loss\n","from sklearn.metrics import log_loss\n","LR_Log_Loss = log_loss(Y_test, predictions)\n","print(\"Log Loss\", log_loss(Y_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### SVM\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"],"text/plain":["SVC()"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import svm\n","SVM = svm.SVC(kernel='rbf')\n","SVM.fit(X_train, Y_train)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["predictions = SVM.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score:  0.7221374045801526\n","Jaccard Index:  0.0\n","F1 Score:  0.0\n"]}],"source":["# Accuracy_Score\n","SVM_Accuracy_Score = accuracy_score(Y_test, predictions)\n","print(\"Accuracy Score: \", accuracy_score(Y_test, predictions))\n","\n","# JaccardIndex \n","SVM_JaccardIndex = jaccard_score(Y_test, predictions)\n","print(\"Jaccard Index: \", jaccard_score(Y_test, predictions))\n","\n","# F1_Score\n","SVM_F1_Score = f1_score(Y_test, predictions)\n","print(\"F1 Score: \", f1_score(Y_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### Report\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n","\n","\\*LogLoss is only for Logistic Regression Model\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                Accuracy Score Jaccard Index  F1-Score  \\\n","Model                                                                    \n","Linear Multivariable Regression            N/A           N/A       N/A   \n","KNN                                   0.812214      0.394089  0.565371   \n","Decision Tree                          0.80458      0.378641  0.549296   \n","Logistic Regression                   0.827481      0.484018  0.652308   \n","Logistic Regression                   0.722137           0.0       0.0   \n","\n","                                  LogLoss Mean Absolute Error  \\\n","Model                                                           \n","Linear Multivariable Regression       N/A            0.256313   \n","KNN                                   N/A                 N/A   \n","Decision Tree                         N/A                 N/A   \n","Logistic Regression              6.218218                 N/A   \n","Logistic Regression                   N/A                 N/A   \n","\n","                                Mean Squared Error  R2-Score  \n","Model                                                         \n","Linear Multivariable Regression           0.115718  0.427144  \n","KNN                                            N/A       N/A  \n","Decision Tree                                  N/A       N/A  \n","Logistic Regression                            N/A       N/A  \n","Logistic Regression                            N/A       N/A  \n"]}],"source":["data = {\n","    'Model': ['Linear Multivariable Regression', 'KNN', 'Decision Tree', 'Logistic Regression', 'Logistic Regression'],\n","    'Accuracy Score': ['N/A', KNN_Accuracy_Score, Tree_Accuracy_Score, LR_Accuracy_Score, SVM_Accuracy_Score],\n","    'Jaccard Index': ['N/A', KNN_JaccardIndex, Tree_JaccardIndex, LR_JaccardIndex, SVM_JaccardIndex],\n","    'F1-Score': ['N/A', KNN4_F1_Score, Tree_F1_Score, LR_F1_Score, SVM_F1_Score],\n","    'LogLoss': ['N/A', 'N/A', 'N/A', LR_Log_Loss, 'N/A'],\n","    'Mean Absolute Error': [LinearRegression_MAE, 'N/A', 'N/A', 'N/A', 'N/A'],\n","    'Mean Squared Error': [LinearRegression_MSE, 'N/A', 'N/A', 'N/A', 'N/A'],\n","    'R2-Score': [LinearRegression_R2, 'N/A', 'N/A', 'N/A', 'N/A']\n","}\n","\n","# Creating the DataFrame\n","Report = pd.DataFrame(data)\n","\n","# Set the 'Model' column as the index\n","Report.set_index('Model', inplace=True)\n","\n","# Display the DataFrame\n","print(Report)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"Section_5\">  How to submit </h2>\n","\n","<p>Once you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n","\n","<p>This will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n","\n","\n","**This final project will be graded by your peers who are completing this course during the same session. This project is worth 53 points**:\n","\n","1.     Splitting the dataset into training and testing data for regression (3 marks)\n","\n","2.     Building and training a model using Linear Regression and calculating evaluation metrics (8 marks)\n","\n","3.     Creating a final regression report/table of evaluation metrics (3 marks)\n","\n","4.     Building and training a model using KNN and calculating evaluation metrics (8 marks)\n","\n","5.     Building and training a model using Decision Trees and calculating evaluation metrics (8 marks)\n","\n","6.     Building and training a model using Logistic Regression and calculating evaluation metrics (9 marks)\n","\n","7.     Building and training a model using SVM and calculating evaluation metrics (8 marks)\n","\n","8.     Creating a final classification report/table of evaluation metrics (3 marks)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":4}
